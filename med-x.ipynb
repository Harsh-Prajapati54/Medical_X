{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839},{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810},{"sourceId":1426603,"sourceType":"datasetVersion","datasetId":835414},{"sourceId":14820042,"sourceType":"datasetVersion","datasetId":9477616},{"sourceId":14820530,"sourceType":"datasetVersion","datasetId":9477979},{"sourceId":14820659,"sourceType":"datasetVersion","datasetId":9478075},{"sourceId":14820783,"sourceType":"datasetVersion","datasetId":9478176},{"sourceId":749316,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":572291,"modelId":584637}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:20.841756Z","iopub.execute_input":"2026-02-16T15:02:20.842496Z","iopub.status.idle":"2026-02-16T15:02:21.256147Z","shell.execute_reply.started":"2026-02-16T15:02:20.842468Z","shell.execute_reply":"2026-02-16T15:02:21.255397Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nprint(\"lib imported\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:21.426925Z","iopub.execute_input":"2026-02-16T15:02:21.427370Z","iopub.status.idle":"2026-02-16T15:02:21.431653Z","shell.execute_reply.started":"2026-02-16T15:02:21.427343Z","shell.execute_reply":"2026-02-16T15:02:21.431068Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image = plt.imread(\"/kaggle/input/data/images_001/images/00000001_000.png\")\nimage.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:22.377048Z","iopub.execute_input":"2026-02-16T15:02:22.377367Z","iopub.status.idle":"2026-02-16T15:02:22.421472Z","shell.execute_reply.started":"2026-02-16T15:02:22.377341Z","shell.execute_reply":"2026-02-16T15:02:22.420759Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.imshow(image,cmap=\"gray\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:23.381838Z","iopub.execute_input":"2026-02-16T15:02:23.382165Z","iopub.status.idle":"2026-02-16T15:02:23.798654Z","shell.execute_reply.started":"2026-02-16T15:02:23.382137Z","shell.execute_reply":"2026-02-16T15:02:23.797984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_label = pd.read_csv(\"/kaggle/input/data/Data_Entry_2017.csv\")\ndata_label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:24.611790Z","iopub.execute_input":"2026-02-16T15:02:24.612115Z","iopub.status.idle":"2026-02-16T15:02:24.882001Z","shell.execute_reply.started":"2026-02-16T15:02:24.612088Z","shell.execute_reply":"2026-02-16T15:02:24.881262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(data_label[[\"Image Index\",\"Finding Labels\",\"Patient ID\"]].head)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:25.766731Z","iopub.execute_input":"2026-02-16T15:02:25.767320Z","iopub.status.idle":"2026-02-16T15:02:25.779292Z","shell.execute_reply.started":"2026-02-16T15:02:25.767291Z","shell.execute_reply":"2026-02-16T15:02:25.778635Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Pre Processing ","metadata":{}},{"cell_type":"markdown","source":"As we can see the finding label has more than one dieseas seprated by `|` \n\nso lets seperate it through One - Hot Encoding using ","metadata":{}},{"cell_type":"code","source":"# List of all 14 diseases\nall_labels = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', \n              'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', \n              'Fibrosis', 'Pleural_Thickening', 'Hernia','No Finding']\n\n# One-hot encode the labels\nfor label in all_labels:\n    data_label[label] = data_label['Finding Labels'].map(lambda x: 1 if label in x else 0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:30.126868Z","iopub.execute_input":"2026-02-16T15:02:30.127456Z","iopub.status.idle":"2026-02-16T15:02:30.661278Z","shell.execute_reply.started":"2026-02-16T15:02:30.127428Z","shell.execute_reply":"2026-02-16T15:02:30.660493Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_label ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:31.051737Z","iopub.execute_input":"2026-02-16T15:02:31.052387Z","iopub.status.idle":"2026-02-16T15:02:31.138868Z","shell.execute_reply.started":"2026-02-16T15:02:31.052359Z","shell.execute_reply":"2026-02-16T15:02:31.138264Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"lets visulize the class imbalances among all the class since it is multilabel classification ","metadata":{}},{"cell_type":"code","source":"import seaborn as sns \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:33.912492Z","iopub.execute_input":"2026-02-16T15:02:33.913200Z","iopub.status.idle":"2026-02-16T15:02:34.686066Z","shell.execute_reply.started":"2026-02-16T15:02:33.913171Z","shell.execute_reply":"2026-02-16T15:02:34.685485Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot the distribution\n# Plot the distribution\nlabel_counts = data_label[all_labels].sum()\nplt.figure(figsize=(12, 6))\nsns.barplot(x=label_counts.values, y=label_counts.index)\nplt.title('Frequency of Diseases in NIH Dataset')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:34.722886Z","iopub.execute_input":"2026-02-16T15:02:34.723515Z","iopub.status.idle":"2026-02-16T15:02:34.937455Z","shell.execute_reply.started":"2026-02-16T15:02:34.723487Z","shell.execute_reply":"2026-02-16T15:02:34.936667Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_label.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:38.362079Z","iopub.execute_input":"2026-02-16T15:02:38.362642Z","iopub.status.idle":"2026-02-16T15:02:38.399631Z","shell.execute_reply.started":"2026-02-16T15:02:38.362612Z","shell.execute_reply":"2026-02-16T15:02:38.398909Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_label.value_counts([\"Unnamed: 11\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:39.172329Z","iopub.execute_input":"2026-02-16T15:02:39.172987Z","iopub.status.idle":"2026-02-16T15:02:39.179292Z","shell.execute_reply.started":"2026-02-16T15:02:39.172957Z","shell.execute_reply":"2026-02-16T15:02:39.178592Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"del data_label[\"Unnamed: 11\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:40.626826Z","iopub.execute_input":"2026-02-16T15:02:40.627545Z","iopub.status.idle":"2026-02-16T15:02:40.631412Z","shell.execute_reply.started":"2026-02-16T15:02:40.627516Z","shell.execute_reply":"2026-02-16T15:02:40.630707Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_label.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:41.765834Z","iopub.execute_input":"2026-02-16T15:02:41.766725Z","iopub.status.idle":"2026-02-16T15:02:41.798767Z","shell.execute_reply.started":"2026-02-16T15:02:41.766694Z","shell.execute_reply":"2026-02-16T15:02:41.798102Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_label[\"No Finding\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:43.807196Z","iopub.execute_input":"2026-02-16T15:02:43.807821Z","iopub.status.idle":"2026-02-16T15:02:43.814226Z","shell.execute_reply.started":"2026-02-16T15:02:43.807794Z","shell.execute_reply":"2026-02-16T15:02:43.813539Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"`No Finding` means the image have no dicease means our data set have an about 60361 clean image  51759 image  is infected ones   ","metadata":{}},{"cell_type":"code","source":"import os\nfrom glob import glob\n\n# Define the root path where your image folders are located\n# On Kaggle, it's usually: /kaggle/input/data/\nimage_root_path = '/kaggle/input/data/' \n\n# This finds all PNGs in any subfolder under the root\nall_image_paths = {os.path.basename(x): x for x in glob(os.path.join(image_root_path, 'images*', 'images', '*.png'))}\n\nprint(f\"Total images found: {len(all_image_paths)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:46.578038Z","iopub.execute_input":"2026-02-16T15:02:46.578644Z","iopub.status.idle":"2026-02-16T15:02:47.915926Z","shell.execute_reply.started":"2026-02-16T15:02:46.578617Z","shell.execute_reply":"2026-02-16T15:02:47.915249Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create the path column\ndata_label['path to images'] = data_label['Image Index'].map(all_image_paths.get)\n\n# Quick check to see if any paths are missing\nmissing_count = data_label['path to images'].isnull().sum()\nif missing_count == 0:\n    print(\"All images mapped successfully!\")\nelse:\n    print(f\"Warning: {missing_count} images could not be found.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:48.082256Z","iopub.execute_input":"2026-02-16T15:02:48.082991Z","iopub.status.idle":"2026-02-16T15:02:48.132619Z","shell.execute_reply.started":"2026-02-16T15:02:48.082962Z","shell.execute_reply":"2026-02-16T15:02:48.131849Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_label.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:50.564744Z","iopub.execute_input":"2026-02-16T15:02:50.565356Z","iopub.status.idle":"2026-02-16T15:02:50.609660Z","shell.execute_reply.started":"2026-02-16T15:02:50.565329Z","shell.execute_reply":"2026-02-16T15:02:50.608998Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\n\n# Plot 3 sample images\nplt.figure(figsize=(15, 5))\nsamples = data_label[data_label['Finding Labels'] != 'No Finding'].sample(3)\n\nfor i, (idx, row) in enumerate(samples.iterrows()):\n    plt.subplot(1, 3, i+1)\n    img = cv2.imread(row['path to images'])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    plt.imshow(img)\n    plt.title(row['Finding Labels'])\n    plt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:53.192717Z","iopub.execute_input":"2026-02-16T15:02:53.193466Z","iopub.status.idle":"2026-02-16T15:02:54.018379Z","shell.execute_reply.started":"2026-02-16T15:02:53.193437Z","shell.execute_reply":"2026-02-16T15:02:54.017575Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_label[\"Patient ID\"].nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:54.727185Z","iopub.execute_input":"2026-02-16T15:02:54.728235Z","iopub.status.idle":"2026-02-16T15:02:54.734394Z","shell.execute_reply.started":"2026-02-16T15:02:54.728181Z","shell.execute_reply":"2026-02-16T15:02:54.733727Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"there are 30805 different patient in the dataset ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import GroupShuffleSplit\n\n# 1. Initialize the splitter for the first split (80% Train, 20% Temp)\nsplitter = GroupShuffleSplit(test_size=0.20, n_splits=1, random_state=42)\n\n# 2. Perform the split\n# Notice we pass 'groups=df['Patient ID']' - this is the magic sauce\nsplit = splitter.split(data_label, groups=data_label['Patient ID'])\ntrain_inds, temp_inds = next(split)\n\n# 3. Create the dataframes\ntrain_df = data_label.iloc[train_inds]\ntemp_df = data_label.iloc[temp_inds]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:57.017576Z","iopub.execute_input":"2026-02-16T15:02:57.017907Z","iopub.status.idle":"2026-02-16T15:02:57.221651Z","shell.execute_reply.started":"2026-02-16T15:02:57.017880Z","shell.execute_reply":"2026-02-16T15:02:57.221007Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:58.092231Z","iopub.execute_input":"2026-02-16T15:02:58.093125Z","iopub.status.idle":"2026-02-16T15:02:58.215598Z","shell.execute_reply.started":"2026-02-16T15:02:58.093095Z","shell.execute_reply":"2026-02-16T15:02:58.214855Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Initialize the splitter for the second split (50% of 20% = 10% total)\nsplitter_val = GroupShuffleSplit(test_size=0.50, n_splits=1, random_state=42)\n\n# 2. Perform the split on the TEMP dataframe\nsplit_val = splitter_val.split(temp_df, groups=temp_df['Patient ID'])\nval_inds, test_inds = next(split_val)\n\n# 3. Create the final dataframes\nval_df = temp_df.iloc[val_inds]\ntest_df = temp_df.iloc[test_inds]\n\nprint(f\"Train Size: {len(train_df)} images\")\nprint(f\"Val Size:   {len(val_df)} images\")\nprint(f\"Test Size:  {len(test_df)} images\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:02:58.883451Z","iopub.execute_input":"2026-02-16T15:02:58.883727Z","iopub.status.idle":"2026-02-16T15:02:58.901797Z","shell.execute_reply.started":"2026-02-16T15:02:58.883705Z","shell.execute_reply":"2026-02-16T15:02:58.901055Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get the unique Patient IDs from each set\ntrain_patients = set(train_df['Patient ID'])\nval_patients = set(val_df['Patient ID'])\ntest_patients = set(test_df['Patient ID'])\n\n# Check for overlaps\nprint(f\"Leakage Train-Val: {len(train_patients.intersection(val_patients))}\")\nprint(f\"Leakage Train-Test: {len(train_patients.intersection(test_patients))}\")\nprint(f\"Leakage Val-Test:   {len(val_patients.intersection(test_patients))}\")\n\n# Assert prevents the code from continuing if there is an error\nassert len(train_patients.intersection(val_patients)) == 0\nassert len(train_patients.intersection(test_patients)) == 0\nassert len(val_patients.intersection(test_patients)) == 0\n\nprint(\"✅ SUCCESS: No Data Leakage detected!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:03:00.472661Z","iopub.execute_input":"2026-02-16T15:03:00.473371Z","iopub.status.idle":"2026-02-16T15:03:00.493095Z","shell.execute_reply.started":"2026-02-16T15:03:00.473342Z","shell.execute_reply":"2026-02-16T15:03:00.492474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:03:02.317091Z","iopub.execute_input":"2026-02-16T15:03:02.317412Z","iopub.status.idle":"2026-02-16T15:03:02.433477Z","shell.execute_reply.started":"2026-02-16T15:03:02.317387Z","shell.execute_reply":"2026-02-16T15:03:02.432825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:03:03.626830Z","iopub.execute_input":"2026-02-16T15:03:03.627120Z","iopub.status.idle":"2026-02-16T15:03:03.654149Z","shell.execute_reply.started":"2026-02-16T15:03:03.627096Z","shell.execute_reply":"2026-02-16T15:03:03.653427Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader , Dataset\nimport numpy as np \nfrom PIL import Image\nimport torchvision.transforms as transforms \n\nclass ChestXrayDataset(Dataset):\n    def __init__(self,dataframe,transform = None):\n        self.dataframe = dataframe\n        self.transform = transform\n        \n        self.all_labels = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', \n                           'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', \n                           'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia']\n    def __len__(self):\n        # Tells the model how many total images are in this set\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        # 1. Get the row for the specific index\n        row = self.dataframe.iloc[idx]\n        \n        # 2. Get the image path and load it\n        img_path = row['path to images']\n        image = Image.open(img_path).convert('RGB') # Ensure it's 3-channel RGB\n        \n        # 3. Get the labels as a numpy array (vector of 0s and 1s)\n        labels = torch.tensor(row[self.all_labels].values.astype(np.float32))\n        \n        # 4. Apply transformations (Resize, Augment, Normalize)\n        if self.transform:\n            image = self.transform(image)\n            \n        return image, labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:03:05.822617Z","iopub.execute_input":"2026-02-16T15:03:05.823187Z","iopub.status.idle":"2026-02-16T15:03:05.828993Z","shell.execute_reply.started":"2026-02-16T15:03:05.823159Z","shell.execute_reply":"2026-02-16T15:03:05.828275Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ImageNet statistics (standard for Transfer Learning)\nnormalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n\n# Training: Add randomness to prevent overfitting\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),      # Flip left-right (allowed)\n    transforms.RandomRotation(10),          # Rotate +/- 10 degrees\n    transforms.ToTensor(),                  # Convert to 0-1 Tensor\n    normalize                               # Subtract mean, divide std\n])\n\n# Validation/Test: No randomness, just resize and normalize\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    normalize\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:03:08.187305Z","iopub.execute_input":"2026-02-16T15:03:08.187839Z","iopub.status.idle":"2026-02-16T15:03:08.192525Z","shell.execute_reply.started":"2026-02-16T15:03:08.187811Z","shell.execute_reply":"2026-02-16T15:03:08.191886Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"create the dataLoader for the data pipeline","metadata":{}},{"cell_type":"code","source":"import os\nNUM_WORKERS = os.cpu_count()\ntrain_dataset = ChestXrayDataset(train_df, transform = train_transform)\ntest_dataset =  ChestXrayDataset(test_df, transform = val_transform)\nval_dataset = ChestXrayDataset(val_df, transform = val_transform)\n\n# create the dataloader for the dataset \ntrain_loader = DataLoader(train_dataset,batch_size = 32 , shuffle=True,num_workers = NUM_WORKERS)\ntest_loader = DataLoader(test_dataset,batch_size = 32, shuffle=False,num_workers = NUM_WORKERS)\nval_loader = DataLoader(val_dataset,batch_size =  32 , shuffle=False,num_workers = NUM_WORKERS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:03:10.621962Z","iopub.execute_input":"2026-02-16T15:03:10.622788Z","iopub.status.idle":"2026-02-16T15:03:10.627860Z","shell.execute_reply.started":"2026-02-16T15:03:10.622753Z","shell.execute_reply":"2026-02-16T15:03:10.627010Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Grab one batch\nimages, labels = next(iter(train_loader))\n\nprint(f\"Image Batch Shape: {images.shape}\") \n# Should be [32, 3, 224, 224] -> 32 images, 3 channels (RGB), 224x224 pixels\n\nprint(f\"Label Batch Shape: {labels.shape}\") \n# Should be [32, 14] -> 32 images, 14 disease labels each\n\nprint(\"✅ Data Pipeline is ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T17:26:22.789426Z","iopub.execute_input":"2026-02-11T17:26:22.789693Z","iopub.status.idle":"2026-02-11T17:26:25.666237Z","shell.execute_reply.started":"2026-02-11T17:26:22.789670Z","shell.execute_reply":"2026-02-11T17:26:25.665339Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train the Model ","metadata":{}},{"cell_type":"markdown","source":"lets use the pre trained model `densenet121` model for our multi label classification , using technique called transfer Learning  ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\nfrom torchinfo import summary\n\n# 1. Define Device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# 2. Instantiate Model\n# Using densenet161 \nmodel = models.densenet121(weights='IMAGENET1K_V1')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T17:26:25.669991Z","iopub.execute_input":"2026-02-11T17:26:25.670251Z","iopub.status.idle":"2026-02-11T17:26:25.869645Z","shell.execute_reply.started":"2026-02-11T17:26:25.670222Z","shell.execute_reply":"2026-02-11T17:26:25.869019Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Modify the Head\nnum_features = model.classifier.in_features\nmodel.classifier = nn.Sequential(\n    nn.Linear(num_features, 14),\n    nn.Sigmoid()\n)\n\n# 4. Move to GPU\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T17:26:25.870519Z","iopub.execute_input":"2026-02-11T17:26:25.870822Z","iopub.status.idle":"2026-02-11T17:26:25.903356Z","shell.execute_reply.started":"2026-02-11T17:26:25.870790Z","shell.execute_reply":"2026-02-11T17:26:25.902666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Get one batch\nimages, labels = next(iter(train_loader))\nimages = images.to(device)\n\n# Run model\nwith torch.no_grad():\n    outputs = model(images)\n    preds = torch.sigmoid(outputs)\n\n# Print the first image's results\nprint(\"--- DEBUGGING ---\")\nprint(f\"Ground Truth (First Image): {labels[0].cpu().numpy()}\")\nprint(f\"Raw Prediction (First Image): {preds[0].cpu().numpy()}\")\nprint(f\"Max Value in Input Image: {images.max().item()}\") # Should be roughly 2.0-3.0 (normalized), NOT 255.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T17:26:25.904377Z","iopub.execute_input":"2026-02-11T17:26:25.904581Z","iopub.status.idle":"2026-02-11T17:26:28.383814Z","shell.execute_reply.started":"2026-02-11T17:26:25.904561Z","shell.execute_reply":"2026-02-11T17:26:28.383027Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. Now run summary\nsummary(model=model, \n        input_size=(32, 3, 224, 224), # (Batch_Size, Channels, Height, Width)\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T17:26:28.385203Z","iopub.execute_input":"2026-02-11T17:26:28.385502Z","iopub.status.idle":"2026-02-11T17:26:28.512601Z","shell.execute_reply.started":"2026-02-11T17:26:28.385471Z","shell.execute_reply":"2026-02-11T17:26:28.511983Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### defining the Loss function and an Optimizer ","metadata":{}},{"cell_type":"code","source":"# define loss function and optimizer\nloss_fun = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T17:26:28.513458Z","iopub.execute_input":"2026-02-11T17:26:28.513731Z","iopub.status.idle":"2026-02-11T17:26:28.518384Z","shell.execute_reply.started":"2026-02-11T17:26:28.513709Z","shell.execute_reply":"2026-02-11T17:26:28.517804Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# calculate the accuracy of the model \ndef accuracy_fn(y_true, y_pred):\n    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n    acc = (correct / len(y_pred)) * 100 \n    return acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T17:26:28.519187Z","iopub.execute_input":"2026-02-11T17:26:28.519415Z","iopub.status.idle":"2026-02-11T17:26:28.528459Z","shell.execute_reply.started":"2026-02-11T17:26:28.519394Z","shell.execute_reply":"2026-02-11T17:26:28.527665Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom tqdm.auto import tqdm\nfrom typing import Dict, List, Tuple\n\ndef train_step(model: torch.nn.Module, \n               dataloader: torch.utils.data.DataLoader, \n               loss_fn: torch.nn.Module, \n               optimizer: torch.optim.Optimizer,\n               device: torch.device) -> Tuple[float, float]:\n    \"\"\"Trains a PyTorch model for a single epoch.\"\"\"\n    # Put model in train mode\n    model.train()\n    \n    # Setup train loss and train accuracy values\n    train_loss, train_acc = 0, 0\n    \n    # Loop through data loader data batches\n    for batch, (X, y) in enumerate(dataloader):\n        # Send data to target device\n        X, y = X.to(device), y.to(device)\n\n        # 1. Forward pass\n        y_pred = model(X)\n\n        # 2. Calculate  and accumulate loss\n        loss = loss_fn(y_pred, y)\n        train_loss += loss.item() \n\n        # 3. Optimizer zero grad\n        optimizer.zero_grad()\n\n        # 4. Loss backward\n        loss.backward()\n\n        # 5. Optimizer step\n        optimizer.step()\n\n        # Calculate and accumulate accuracy metric across all batches\n        # 1. Turn raw outputs (logits) into independent probabilities (0 to 1)\n        y_pred_probs = y_pred\n\n        # 2. Convert probabilities to binary predictions (0 or 1) based on 50% threshold\n        y_pred_binary = (y_pred_probs > 0.5).float()\n\n        # 3. Compare with the ground truth labels\n        train_acc += (y_pred_binary == y).sum().item() / (y.size(0) * y.size(1))\n\n    # Adjust metrics to get average loss and accuracy per batch \n    train_loss = train_loss / len(dataloader)\n    train_acc = train_acc / len(dataloader)\n    return train_loss, train_acc\n\ndef test_step(model: torch.nn.Module, \n              dataloader: torch.utils.data.DataLoader, \n              loss_fn: torch.nn.Module,\n              device: torch.device) -> Tuple[float, float]:\n    \"\"\"Tests a PyTorch model for a single epoch.\"\"\"\n    # 1. Put model in evaluation mode\n    model.eval() \n    \n    # Setup test loss and test accuracy values\n    test_loss, test_acc = 0, 0\n    \n    # 2. Turn on inference context manager (saves memory)\n    with torch.inference_mode():\n        # Loop through DataLoader batches\n        for batch, (X, y) in enumerate(dataloader):\n            # Send data to target device\n            X, y = X.to(device), y.to(device)\n            \n            # 1. Forward pass\n            y_pred = model(X)\n\n            # 2. Calculate and accumulate loss\n            loss = loss_fn(y_pred, y)\n            test_loss += loss.item()\n            \n            # 3. Calculate and accumulate accuracy\n            y_pred_probs = y_pred\n            y_pred_binary = (y_pred_probs > 0.5).float()\n            test_acc += (y_pred_binary == y).sum().item() / (y.size(0) * y.size(1))\n            \n    # Adjust metrics to get average loss and accuracy per batch \n    test_loss = test_loss / len(dataloader)\n    test_acc = test_acc / len(dataloader)\n    return test_loss, test_acc\n\ndef train(model: torch.nn.Module, \n          train_dataloader: torch.utils.data.DataLoader, \n          test_dataloader: torch.utils.data.DataLoader, \n          optimizer: torch.optim.Optimizer,\n          loss_fn: torch.nn.Module,\n          epochs: int,\n          device: torch.device) -> Dict[str, List]:\n    \"\"\"Trains and tests a PyTorch model.\"\"\"\n    # Create empty results dictionary\n    results = {\"train_loss\": [],\n        \"train_acc\": [],\n        \"test_loss\": [],\n        \"test_acc\": []\n    }\n    \n    # Loop through training and testing steps for a number of epochs\n    for epoch in tqdm(range(epochs)):\n        train_loss, train_acc = train_step(model=model,\n                                           dataloader=train_dataloader,\n                                           loss_fn=loss_fn,\n                                           optimizer=optimizer,\n                                           device=device)\n        test_loss, test_acc = test_step(model=model,\n                                        dataloader=test_dataloader,\n                                        loss_fn=loss_fn,\n                                        device=device)\n        \n        # Print out what's happening\n        print(\n            f\"Epoch: {epoch+1} | \"\n            f\"train_loss: {train_loss:.4f} | \"\n            f\"train_acc: {train_acc:.4f} | \"\n            f\"test_loss: {test_loss:.4f} | \"\n            f\"test_acc: {test_acc:.4f}\"\n        )\n\n        # Update results dictionary\n        results[\"train_loss\"].append(train_loss)\n        results[\"train_acc\"].append(train_acc)\n        results[\"test_loss\"].append(test_loss)\n        results[\"test_acc\"].append(test_acc)\n\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T17:26:28.529356Z","iopub.execute_input":"2026-02-11T17:26:28.529568Z","iopub.status.idle":"2026-02-11T17:26:28.549559Z","shell.execute_reply.started":"2026-02-11T17:26:28.529548Z","shell.execute_reply":"2026-02-11T17:26:28.548921Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train the model\ntorch.manual_seed(42)\n\nfrom timeit import default_timer as timer\nstart_time = timer()\n\nresults = train(model=model,\n                train_dataloader=train_loader,\n                test_dataloader=test_loader,\n                optimizer=optimizer,\n                loss_fn=loss_fun,\n                epochs=15,\n                device=device)\nend_time = timer()\nprint(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-11T17:26:28.550956Z","iopub.execute_input":"2026-02-11T17:26:28.551207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model_weights.pth')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nfrom torchvision import models, transforms\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom typing import List, Tuple\n\n# ---------------------------------------------------------\n# 1. SETUP DEVICE & MODEL (The Fixes)\n# ---------------------------------------------------------\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Running on: {device}\")\n\n# Define Model Architecture\nmodel = models.densenet121(weights=None) # weights=None because we load our own\n\n# FIX: Wrap classifier in nn.Sequential to match saved keys (\"classifier.0.weight\")\nnum_ftrs = model.classifier.in_features\nnum_classes = 14  # <--- CHANGE TO YOUR NUMBER OF CLASSES\nmodel.classifier = nn.Sequential(\n    nn.Linear(num_ftrs, num_classes)\n)\n\n# Load Weights (Safe for CPU/GPU)\nmodel_path = '/kaggle/input/models/harshprajapati83/my-model/pytorch/default/1/model_weights.pth' # <--- UPDATE PATH\ntry:\n    state_dict = torch.load(model_path, map_location=device)\n    model.load_state_dict(state_dict)\n    print(\"Model weights loaded successfully.\")\nexcept Exception as e:\n    print(f\"Error loading weights: {e}\")\n\n# Move to device\nmodel = model.to(device)\n\n# ---------------------------------------------------------\n# 2. YOUR PREDICTION FUNCTION\n# ---------------------------------------------------------\ndef pred_and_plot_image(model: torch.nn.Module,\n                        image_path: str,\n                        class_names: List[str],\n                        image_size: Tuple[int, int] = (224, 224),\n                        transform: torchvision.transforms = None,\n                        device: torch.device = device):\n\n    # 1. Open image and convert to RGB\n    img = Image.open(image_path).convert('RGB')\n\n    # 2. Create transformation for image (if one doesn't exist)\n    if transform is not None:\n        image_transform = transform\n    else:\n        # Default transform (Ensure this matches your training!)\n        image_transform = transforms.Compose([\n            transforms.Resize(image_size),\n            transforms.ToTensor(),\n            # Common ImageNet normalization (adjust if you didn't use this in training)\n            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225]),\n        ])\n\n    ### Predict on image ###\n\n    # 3. Make sure the model is on the target device\n    model.to(device)\n\n    # 4. Turn on model evaluation mode and inference mode\n    model.eval()\n    with torch.inference_mode():\n        # 5. Transform and add an extra dimension to image (Batch dimension)\n        transformed_image = image_transform(img).unsqueeze(dim=0)\n\n        # 6. Make a prediction on image with an extra dimension\n        # Move the input tensor to the same device as the model\n        target_image_pred = model(transformed_image.to(device))\n\n    # 7. Convert logits -> prediction probabilities\n    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n\n    # 8. Convert prediction probabilities -> prediction labels\n    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n\n    # 9. Plot image with predicted label and probability\n    plt.figure()\n    plt.imshow(img) # Show original image\n    \n    pred_label = class_names[target_image_pred_label]\n    pred_prob = target_image_pred_probs.max()\n    \n    plt.title(f\"Pred: {pred_label} | Prob:{pred_prob:.3f}\")\n    plt.axis(False)\n    plt.show() # Explicitly show the plot\n\n# ---------------------------------------------------------\n# 3. EXAMPLE USAGE\n# ---------------------------------------------------------","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:01:36.614013Z","iopub.execute_input":"2026-02-16T15:01:36.614231Z","iopub.status.idle":"2026-02-16T15:01:45.607856Z","shell.execute_reply.started":"2026-02-16T15:01:36.614188Z","shell.execute_reply":"2026-02-16T15:01:45.607164Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define your class names (Must be in the same order as training indices 0, 1, etc.)\nclass_names = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', \n                           'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', \n                           'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia'] \n\n# Call the function\npred_and_plot_image(model=model, \n                     image_path=\"/kaggle/input/custom/pneumonia4.jpeg\", \n                     class_names=class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:01:45.609488Z","iopub.execute_input":"2026-02-16T15:01:45.609810Z","iopub.status.idle":"2026-02-16T15:01:46.680152Z","shell.execute_reply.started":"2026-02-16T15:01:45.609785Z","shell.execute_reply":"2026-02-16T15:01:46.679459Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Roc & Auc Score and F1 score ","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, f1_score\nimport numpy as np\n\n# 1. Get all predictions and truths from the validation set\nall_preds = []\nall_targets = []\nmodel.eval()\nwith torch.no_grad():\n    for X, y in val_loader:\n        X, y = X.to(device), y.to(device)\n        preds = torch.sigmoid(model(X))\n        all_preds.append(preds.cpu().numpy())\n        all_targets.append(y.cpu().numpy())\n\nall_preds = np.concatenate(all_preds)\nall_targets = np.concatenate(all_targets)\n\n# 2. Calculate AUC and Best Threshold for each class\ndiseases = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', \n            'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', \n            'Fibrosis', 'Pleural_Thickening', 'Hernia']\n\nprint(f\"{'Disease':<20} | {'AUC':<6} | {'Best Thresh':<12} | {'F1 Score'}\")\nprint(\"-\" * 60)\n\nfor i, disease in enumerate(diseases):\n    # Calculate AUC\n    auc = roc_auc_score(all_targets[:, i], all_preds[:, i])\n    \n    # Find optimal threshold (simple grid search)\n    best_thresh = 0.5\n    best_f1 = 0\n    for thresh in np.arange(0.1, 0.9, 0.05):\n        f1 = f1_score(all_targets[:, i], (all_preds[:, i] > thresh).astype(int))\n        if f1 > best_f1:\n            best_f1 = f1\n            best_thresh = thresh\n            \n    print(f\"{disease:<20} | {auc:.3f}  | {best_thresh:.3f}        | {best_f1:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T16:27:49.224220Z","iopub.execute_input":"2026-02-12T16:27:49.224511Z","iopub.status.idle":"2026-02-12T16:29:43.804288Z","shell.execute_reply.started":"2026-02-12T16:27:49.224486Z","shell.execute_reply":"2026-02-12T16:29:43.803501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.metrics import f1_score\n\ndef get_optimal_thresholds(model, dataloader, device):\n    model.eval()\n    all_targets = []\n    all_probs = []\n    \n    # 1. Gather all predictions from the validation set\n    print(\"Gathering predictions...\")\n    with torch.no_grad():\n        for X, y in dataloader:\n            X, y = X.to(device), y.to(device)\n            outputs = torch.sigmoid(model(X))\n            all_probs.append(outputs.cpu().numpy())\n            all_targets.append(y.cpu().numpy())\n            \n    all_probs = np.concatenate(all_probs)\n    all_targets = np.concatenate(all_targets)\n    \n    best_thresholds = []\n    disease_names = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', \n                     'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', \n                     'Fibrosis', 'Pleural_Thickening', 'Hernia']\n    \n    print(\"\\nOPTIMAL THRESHOLDS FOUND:\")\n    print(\"-\" * 50)\n    print(f\"{'Disease':<20} | {'Best Thresh':<10} | {'F1 Score'}\")\n    print(\"-\" * 50)\n\n    # 2. Iterate through each of the 14 diseases\n    for i in range(14):\n        best_f1 = 0\n        best_thresh = 0.5 # Default\n        \n        # Test thresholds from 0.05 to 0.50\n        # We focus on low thresholds because diseases are rare!\n        for thresh in np.arange(0.05, 0.55, 0.01):\n            preds = (all_probs[:, i] > thresh).astype(int)\n            f1 = f1_score(all_targets[:, i], preds)\n            \n            if f1 > best_f1:\n                best_f1 = f1\n                best_thresh = thresh\n        \n        best_thresholds.append(best_thresh)\n        print(f\"{disease_names[i]:<20} | {best_thresh:.3f}      | {best_f1:.4f}\")\n        \n    return best_thresholds\n\n# RUN THE SOLVER\n# Assuming 'model' and 'val_loader' are already defined\noptimal_thresholds = get_optimal_thresholds(model, val_loader, device)\nprint(f\"\\nFinal Threshold List: {optimal_thresholds}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-12T16:49:32.280153Z","iopub.execute_input":"2026-02-12T16:49:32.280481Z","iopub.status.idle":"2026-02-12T16:51:20.416736Z","shell.execute_reply.started":"2026-02-12T16:49:32.280452Z","shell.execute_reply":"2026-02-12T16:51:20.415905Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_disease(image_path, model, thresholds):\n    # Load and Preprocess\n    img = Image.open(image_path).convert('RGB')\n    img_tensor = val_transform(img).unsqueeze(0).to(device) # Add batch dim\n    \n    # Get Probability\n    model.eval()\n    with torch.no_grad():\n        prob = torch.sigmoid(model(img_tensor)).cpu().numpy()[0]\n    \n    # Apply Specific Thresholds\n    predictions = [0.18,0.08,0.26,0.18,0.18,0.17,0.06,0.1,0.13,0.26,0.17,0.09,0.13,0.13]\n    diseases = ['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', 'Mass', 'Nodule', \n                'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema', 'Emphysema', \n                'Fibrosis', 'Pleural_Thickening', 'Hernia']\n                \n    print(f\"Predictions for {image_path}:\")\n    for i, disease in enumerate(diseases):\n        # The Magic Fix: Compare probability to the optimal threshold\n        if prob[i] > thresholds[i]:\n            print(f\"⚠️ POSITIVE: {disease} (Conf: {prob[i]:.2f} > Thresh: {thresholds[i]:.2f})\")\n            predictions.append(disease)\n        else:\n            print(\"✅ No findings (Healthy)\")# Optional: Print negatives to see how close they were\n\n        \n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:01:57.356491Z","iopub.execute_input":"2026-02-16T15:01:57.357277Z","iopub.status.idle":"2026-02-16T15:01:57.363317Z","shell.execute_reply.started":"2026-02-16T15:01:57.357243Z","shell.execute_reply":"2026-02-16T15:01:57.362606Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. Define the path to a test image\ntest_image_path = \"/kaggle/input/pneumothrox/pneumothrox.jpg\"\n\n# 2. Define your thresholds (Use the ones you calculated, or a default list)\n# If you ran the \"Solver\" code, use: optimal_thresholds\n# If you didn't, use 0.5 for everything:\noptimal_thresholds = [0.18,0.08,0.26,0.18,0.18,0.17,0.06,0.1,0.13,0.26,0.17,0.09,0.13,0.13] \n\n# 3. Call the function\nmy_predictions = predict_disease(\n    image_path=test_image_path,\n    model=model, \n    thresholds=optimal_thresholds  # OR use default_thresholds\n)\n\n# Output: ['Infiltration', 'Mass']\nprint(\"Final Result:\", my_predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T15:03:19.511990Z","iopub.execute_input":"2026-02-16T15:03:19.512397Z","iopub.status.idle":"2026-02-16T15:03:19.557716Z","shell.execute_reply.started":"2026-02-16T15:03:19.512370Z","shell.execute_reply":"2026-02-16T15:03:19.557042Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Gradient Cam \n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\n\n# 1. Initialize architecture\nmodel = models.densenet121(weights=None)\nnum_ftrs = model.classifier.in_features\nmodel.classifier = nn.Sequential(\n    nn.Linear(num_ftrs, 14)\n) # Match your 14 classes\n\n# 2. Load weights (handling the 'module.' prefix just in case)\nstate_dict = torch.load('/kaggle/input/models/harshprajapati83/my-model/pytorch/default/1/model_weights.pth', map_location='cpu')\nfrom collections import OrderedDict\nnew_state_dict = OrderedDict()\nfor k, v in state_dict.items():\n    name = k[7:] if k.startswith('module.') else k\n    new_state_dict[name] = v\n\nmodel.load_state_dict(new_state_dict)\nmodel.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T18:19:05.794473Z","iopub.execute_input":"2026-02-19T18:19:05.794864Z","iopub.status.idle":"2026-02-19T18:19:06.100650Z","shell.execute_reply.started":"2026-02-19T18:19:05.794832Z","shell.execute_reply":"2026-02-19T18:19:06.099694Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DenseNet(\n  (features): Sequential(\n    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu0): ReLU(inplace=True)\n    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (denseblock1): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition1): _Transition(\n      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock2): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition2): _Transition(\n      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock3): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer13): _DenseLayer(\n        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer14): _DenseLayer(\n        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer15): _DenseLayer(\n        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer16): _DenseLayer(\n        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer17): _DenseLayer(\n        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer18): _DenseLayer(\n        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer19): _DenseLayer(\n        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer20): _DenseLayer(\n        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer21): _DenseLayer(\n        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer22): _DenseLayer(\n        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer23): _DenseLayer(\n        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer24): _DenseLayer(\n        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition3): _Transition(\n      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock4): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer13): _DenseLayer(\n        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer14): _DenseLayer(\n        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer15): _DenseLayer(\n        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer16): _DenseLayer(\n        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (classifier): Sequential(\n    (0): Linear(in_features=1024, out_features=14, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport torch.nn.functional as F\n\nclass GradCAM:\n    def __init__(self, model, target_layer):\n        self.model = model\n        self.target_layer = target_layer\n        self.gradients = None\n        self.activations = None\n        \n        # Hooks to capture forward and backward passes\n        self.target_layer.register_forward_hook(self.save_activation)\n        self.target_layer.register_full_backward_hook(self.save_gradient)\n\n    def save_activation(self, module, input, output):\n        self.activations = output\n\n    def save_gradient(self, module, grad_input, grad_output):\n        self.gradients = grad_output[0]\n\n    def generate_heatmap(self, input_tensor, class_idx):\n        # Forward pass\n        output = self.model(input_tensor)\n        \n        # Backward pass for the specific class\n        self.model.zero_grad()\n        loss = output[0, class_idx]\n        loss.backward()\n\n        # Global average pooling of gradients\n        weights = torch.mean(self.gradients, dim=(2, 3), keepdim=True)\n        \n        # Weighted combination of forward activation maps\n        cam = torch.sum(weights * self.activations, dim=1).squeeze()\n        \n        # ReLU and Normalization\n        cam = F.relu(cam)\n        cam -= cam.min()\n        cam /= cam.max()\n        return cam.detach().cpu().numpy()\n\n# Usage for DenseNet121: \n# The last conv layer is usually model.features.norm5\ntarget_layer = model.features.norm5 \ngcam = GradCAM(model, target_layer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T18:19:54.310274Z","iopub.execute_input":"2026-02-19T18:19:54.310873Z","iopub.status.idle":"2026-02-19T18:19:54.664185Z","shell.execute_reply.started":"2026-02-19T18:19:54.310840Z","shell.execute_reply":"2026-02-19T18:19:54.663420Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def visualize_cam(img_path, heatmap):\n    img = cv2.imread(img_path)\n    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n    heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n    \n    # Superimpose the heatmap on original image\n    result = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)\n    cv2.imwrite('gradcam_result.jpg', result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T18:20:49.064224Z","iopub.execute_input":"2026-02-19T18:20:49.064955Z","iopub.status.idle":"2026-02-19T18:20:49.070247Z","shell.execute_reply.started":"2026-02-19T18:20:49.064882Z","shell.execute_reply":"2026-02-19T18:20:49.069287Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Example execution\nheatmap = gcam.generate_heatmap(your_input_tensor, class_idx=5)\nvisualize_cam('/kaggle/input/pneumothrox/pneumothrox.jpg', heatmap)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-19T18:21:10.514129Z","iopub.execute_input":"2026-02-19T18:21:10.514487Z","iopub.status.idle":"2026-02-19T18:21:10.522019Z","shell.execute_reply.started":"2026-02-19T18:21:10.514456Z","shell.execute_reply":"2026-02-19T18:21:10.520846Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2719177860.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Example execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myour_input_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvisualize_cam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/kaggle/input/pneumothrox/pneumothrox.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheatmap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'your_input_tensor' is not defined"],"ename":"NameError","evalue":"name 'your_input_tensor' is not defined","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}